{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "orchid-gd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babelfishz/colab-models/blob/master/orchid_gd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI_44CTJCBgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwZ3mkPkdMsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM5xTC643YiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "#!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqixy4bFqAq9",
        "colab_type": "code",
        "outputId": "aa024b37-4705-4351-bfcc-1014411571da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q0dvjtApoJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import  Dropout, Input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eryVCI3puK3",
        "colab_type": "code",
        "outputId": "2eb0939f-8115-4b21-f7b7-5da93bbaa81b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_path = './gdrive/My Drive/dataSet/train'\n",
        "valid_path = './gdrive/My Drive/dataSet/val'\n",
        "test_path = './gdrive/My Drive/dataSet/test'\n",
        "\n",
        "train_batches = ImageDataGenerator().flow_from_directory(train_path,target_size=(224,224),  batch_size=32)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path,target_size=(224,224),  batch_size=32)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224),  batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 188 images belonging to 3 classes.\n",
            "Found 18 images belonging to 3 classes.\n",
            "Found 18 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7r4OuUyaVJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_model = tensorflow.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "for layer in vgg16_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Create the model\n",
        "model = Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg16_model)\n",
        " \n",
        "# Add new layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tensorflow.keras.optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_batches, \n",
        "            epochs=5, \n",
        "            validation_data=valid_batches, \n",
        "            steps_per_epoch=train_batches.samples/train_batches.batch_size,\n",
        "            validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "            verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wgjsVyVkXds7",
        "colab": {}
      },
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "\n",
        "predictions = model.predict(test_imgs)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiOWWA6MKh1G",
        "colab_type": "code",
        "outputId": "b4d292db-166d-4b4a-aa33-629ddf118e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "tf.keras.models.save_model(model, \"./gdrive/My Drive/_models/flower/1\")\n",
        "print(\"models written\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/_models/flower/1/assets\n",
            "models written\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Kn11cCsBY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model = tf.keras.models.load_model(\"./gdrive/My Drive/_models/flower/1\")\n",
        "input_shape = (None, 224, 224, 3)\n",
        "saved_model.build(input_shape)\n",
        "saved_model.summary()\n",
        "\n",
        "#imported = tf.saved_model.load(\"/content/gdrive/My Drive/Models/flower/1\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2jvfbm6qs8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "\n",
        "predictions = saved_model.predict(test_imgs)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZNour1ljjyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_b64_image(image_bytes, h=224, w=224):\n",
        "    image = tf.io.decode_base64(image_bytes[0])\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, size=[h, w])\n",
        "    #image = (image - 127.5) / 127.5\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    return image\n",
        "\n",
        "#image_bytes = Input(shape = (1,),dtype=\"string\")\n",
        "image_bytes = tf.keras.Input(shape=[], batch_size=1, name='b64_image_bytes', dtype=tf.string)\n",
        "preprocessed_image = preprocess_b64_image(image_bytes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8pLxK6OneE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = saved_model(preprocessed_image)\n",
        "new_model = tf.keras.Model(image_bytes, predictions)\n",
        "new_model.summary()\n",
        "print('Model Input Shape:', new_model.input_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khpj0nO1jwHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOm7oxyifh33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def preprocess_and_decode(img_str, new_shape=[224,224]):\n",
        "    img = tf.io.decode_base64(img_str)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, new_shape, method=tf.image.ResizeMethod.BILINEAR)\n",
        "    # if you need to squeeze your input range to [0,1] or [-1,1] do it here\n",
        "    return img\n",
        "InputLayer = Input(shape = (1,),dtype=\"string\")\n",
        "OutputLayer = tf.keras.layers.Lambda(lambda img : tf.map_fn(lambda im : preprocess_and_decode(im[0]), img, dtype=\"float32\"))(InputLayer)\n",
        "base64_model = tf.keras.Model(InputLayer,OutputLayer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKb4RT2n3XmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base64_input = base64_model.input\n",
        "final_output = saved_model(base64_model.output)\n",
        "new_model = tf.keras.Model(base64_input,final_output)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzxopp7mL-Oq",
        "colab_type": "code",
        "outputId": "0265ccca-5821-4573-949c-7a9a2f4d985b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.keras.models.save_model(new_model, \"./gdrive/My Drive/_models/flower/2\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/_models/flower/2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxkBOVq361FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_saved_model = tf.keras.models.load_model(\"./gdrive/My Drive/_models/flower/2\")\n",
        "new_saved_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVA9_THbwjDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja4aKPVBcOoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f2b9237c-f9d1-4a76-e570-abb65c449b6d"
      },
      "source": [
        "\n",
        "import base64\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "url = \"http://47.88.158.181:8501/v1/models/flower:predict\"\n",
        "\n",
        "with open('3.jpg', \"rb\") as img_file:\n",
        "  encoded_string = base64.urlsafe_b64encode(img_file.read()).decode(\"utf-8\")\n",
        "data = json.dumps({\"instances\": [{\"b64_image_bytes\": encoded_string}]})\n",
        "\n",
        "r = requests.post(url = url, data = data)\n",
        "r.json()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'predictions': [[0.000492823776, 3.64402258e-05, 0.99947077]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqQoTYhSF9As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots images with labels within jupyter notebook\n",
        "def plots(ims, figsize=(24,12), rows=6, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=32)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "#imgs, labels = next(train_batches)\n",
        "#plots(imgs, titles=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BudCDVhr6j9m",
        "colab_type": "code",
        "outputId": "71a578d1-787c-4f2a-9e9f-391ed4b6c5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!saved_model_cli show --dir ./gdrive/My\\ Drive/_models/flower/2 --all"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['b64_image_bytes'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (1)\n",
            "        name: serving_default_b64_image_bytes:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['sequential'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (1, 3)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0413 13:57:52.241466 140193101354880 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          b64_image_bytes: TensorSpec(shape=(None,), dtype=tf.string, name=u'b64_image_bytes')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          b64_image_bytes: TensorSpec(shape=(None,), dtype=tf.string, name=u'b64_image_bytes')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          b64_image_bytes: TensorSpec(shape=(None,), dtype=tf.string, name=u'b64_image_bytes')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          b64_image_bytes: TensorSpec(shape=(None,), dtype=tf.string, name=u'b64_image_bytes')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          b64_image_bytes: TensorSpec(shape=(None,), dtype=tf.string, name=u'b64_image_bytes')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}